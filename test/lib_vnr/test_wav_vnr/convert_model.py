import argparse
import os.path
import subprocess
import tensorflow as tf
import numpy as np
from xmos_ai_tools import xcore_tflm_host_interpreter as xtflm

this_filepath = os.path.dirname(os.path.abspath(__file__))

def parse_arguments():
    parser = argparse.ArgumentParser()
    parser.add_argument("xcore_opt_tflite_model", nargs='?',
                        help=".xe file to run")
    args = parser.parse_args()
    return args

def get_quant_spec(model):
    interpreter_tflite = tf.lite.Interpreter(model_path=str(model))
    input_details = interpreter_tflite.get_input_details()[0]
    output_details = interpreter_tflite.get_output_details()[0]    

    assert(input_details["dtype"] in [np.int8, np.uint8]),"Error: Only 8bit input supported"
    assert(output_details["dtype"] in [np.int8, np.uint8]),"Error: Only 8bit output supported"

    # quantization spec
    input_scale, input_zero_point = input_details["quantization"]
    output_scale, output_zero_point = output_details["quantization"]
    return input_scale, input_zero_point, output_scale, output_zero_point

if __name__ == "__main__":
    args = parse_arguments()
    model = args.xcore_opt_tflite_model
    model = os.path.abspath(model)
    print(f"model file = {model}")

    parent_dir = os.path.dirname(os.path.abspath(model))

    test_dir = os.path.join(parent_dir, "new")
    os.makedirs(test_dir, exist_ok=True)

    # Tflite to xcore optimised tflite
    xcore_opt_model = os.path.join(test_dir, os.path.basename(model).split('.')[0] + "_xcore.tflite")
    convert_cmd = f"xcore-opt --xcore-thread-count 1 -o {xcore_opt_model} {model}".split()
    subprocess.run(convert_cmd)
    
    # Convert tflite to .c and .h files
    c_file_name = os.path.join(test_dir, "vnr_model_data.c")
    h_file_name = os.path.join(test_dir, "vnr_model_data.h")
    tflite_to_c_script = os.path.join(this_filepath, "../../../tools/tflite_micro/convert_tflite_to_c_source.py")
    cmd = f"{tflite_to_c_script} --input {xcore_opt_model} --header {h_file_name} --source {c_file_name} --variable-name vnr".split()
    subprocess.run(cmd)
    
    # Tensor arena size
    ie = xtflm.XTFLMInterpreter(model_path=xcore_opt_model)
    ie.allocate_tensors()
    print(f"Tensor arena size = {ie.tensor_arena_size} bytes")
    with open(os.path.join(test_dir, "vnr_tensor_arena_size.h"), "w") as fp:
        fp.write(f"// Autogenerated from {os.path.abspath(__file__)}. Do not modify\n\n")
        fp.write("#ifndef VNR_TENSOR_ARENA_SIZE_H\n")
        fp.write("#define VNR_TENSOR_ARENA_SIZE_H\n\n")
        fp.write(f"#define TENSOR_ARENA_SIZE_BYTES    ({ie.tensor_arena_size})\n")
        fp.write("\n\n#endif")

    input_scale, input_zero_point, output_scale, output_zero_point = get_quant_spec(model)
    print(input_scale, input_zero_point, output_scale, output_zero_point)
    with open(os.path.join(test_dir, "vnr_quant_spec_defines.h"), "w") as fp:
        fp.write(f"// Autogenerated from {os.path.abspath(__file__)}. Do not modify\n\n")
        fp.write("#ifndef VNR_QUANT_SPEC_DEFINES_H\n")
        fp.write("#define VNR_QUANT_SPEC_DEFINES_H\n\n")
        fp.write(f"#define VNR_INPUT_SCALE_INV    (1/{input_scale})\n")
        fp.write(f"#define VNR_INPUT_ZERO_POINT   ({input_zero_point})\n")
        fp.write(f"#define VNR_OUTPUT_SCALE       ({output_scale})\n")
        fp.write(f"#define VNR_INPUT_ZERO_POINT   ({output_zero_point})\n")
        fp.write("\n\n#endif")

